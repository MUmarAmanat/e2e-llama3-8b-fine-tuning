{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f8868d7-85f7-4b8b-92fa-37cd8316bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from s3fs) (1.35.4)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from s3fs) (2024.6.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install s3fs\n",
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c8ea9b0-3165-4f8b-8c07-40eb618b8bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152a016-ea3f-44e5-aaf5-1b370a57367f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743df47b-0698-4130-9bcf-43a51aab823f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"job-skill-s3\"\n",
    "DATA_DIR = \"raw_dataset\"\n",
    "CSV_FILE = \"job_title_des.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a863fe12-93d5-428f-abc0-936a911e424b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket_name = sess.default_bucket()\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36345203-0c54-4c88-95e4-e1c9e8d6e8ee",
   "metadata": {},
   "source": [
    "## Reading Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3939bc-38eb-4802-9575-542f556644e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e492d89-02be-40c2-a1c5-4dde99f21b90",
   "metadata": {},
   "source": [
    "Copy s3 file to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f835d6-469c-4daf-948b-09ed522c3a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4272e34b-d0f1-4af1-9551-490b3214977e",
   "metadata": {},
   "source": [
    "__NOTE__: Make sure you have access to read object from s3, otherwise create and attach policy according to your reqruiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d33fffd-ab16-4199-914d-f6dfe9449d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/fsspec/registry.py:279: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "job_df = pd.read_csv(f\"s3://{os.path.join(BUCKET_NAME, DATA_DIR, CSV_FILE)}\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff1cd20-da1f-4e5a-a8ba-77acefeea397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flutter Developer</td>\n",
       "      <td>We are looking for hire experts flutter develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Django Developer</td>\n",
       "      <td>PYTHON/DJANGO (Developer/Lead) - Job Code(PDJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Data Scientist (Contractor)\\n\\nBangalore, IN\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iOS Developer</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nStrong framework outside o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>job responsibility full stack engineer – react...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Job Title                                    Job Description\n",
       "0     Flutter Developer  We are looking for hire experts flutter develo...\n",
       "1      Django Developer  PYTHON/DJANGO (Developer/Lead) - Job Code(PDJ ...\n",
       "2      Machine Learning  Data Scientist (Contractor)\\n\\nBangalore, IN\\n...\n",
       "3         iOS Developer  JOB DESCRIPTION:\\n\\nStrong framework outside o...\n",
       "4  Full Stack Developer  job responsibility full stack engineer – react..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83946aa5-51a9-4fa4-9602-ee86a59f3a44",
   "metadata": {},
   "source": [
    "Target variable distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9968c3b-b43e-4106-843b-ae31b4e60724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript Developer      166\n",
       "Java Developer            161\n",
       "Software Engineer         160\n",
       "Node js developer         160\n",
       "iOS Developer             159\n",
       "PHP Developer             156\n",
       "Flutter Developer         155\n",
       "DevOps Engineer           155\n",
       "Django Developer          152\n",
       "Machine Learning          152\n",
       "Backend Developer         147\n",
       "Network Administrator     145\n",
       "Database Administrator    139\n",
       "Full Stack Developer      138\n",
       "Wordpress Developer       132\n",
       "Name: Job Title, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b4db77-4b5e-4b1d-b9ff-7281e60664c0",
   "metadata": {},
   "source": [
    "Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77fc2e4a-4bc2-44c5-98f6-b269d427894b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_df['Target_cat'] = job_df['Job Title'].astype('category')\n",
    "job_df['Target'] = job_df['Target_cat'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea822781-20ba-4b44-9df6-b2af3c96db91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Backend Developer',\n",
       " 1: 'Database Administrator',\n",
       " 2: 'DevOps Engineer',\n",
       " 3: 'Django Developer',\n",
       " 4: 'Flutter Developer',\n",
       " 5: 'Full Stack Developer',\n",
       " 6: 'Java Developer',\n",
       " 7: 'JavaScript Developer',\n",
       " 8: 'Machine Learning',\n",
       " 9: 'Network Administrator',\n",
       " 10: 'Node js developer',\n",
       " 11: 'PHP Developer',\n",
       " 12: 'Software Engineer',\n",
       " 13: 'Wordpress Developer',\n",
       " 14: 'iOS Developer'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_map = {code: category for code, category in enumerate(job_df['Target_cat'].cat.categories)}\n",
    "category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33faeb-6e0b-4a28-8a22-932de6c50201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8335a727-0bd5-4285-9eaf-39b25e2758a9",
   "metadata": {},
   "source": [
    "## Save Categories for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d325583-63db-4d9a-98db-e816d1f6cbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## category map\n",
    "with open(r\"./job_category.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(category_map, output_file)\n",
    "    \n",
    "    \n",
    "# with open('./category_map.pickle', 'rb') as fp:\n",
    "#     print(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735eb830-ea0e-4fcc-945b-bb83509854af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac10b62d-99ff-46e8-bdd0-bdc44cd8366a",
   "metadata": {},
   "source": [
    "It's better not to split data randomly, especially with imbalanced datasets with many labels, as it can lead to train, test, and validation sets having different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "671e58ef-3d15-4b38-b484-84478ecfa640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to split data for each category\n",
    "def split_data(group):\n",
    "    train, temp = train_test_split(group, test_size=0.2, random_state=42)  # 80% train, 20% temp\n",
    "    val, test = train_test_split(temp, test_size=0.5, random_state=42)     # 50% of temp -> 10% val, 10% test\n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a133861-36df-4d65-8cca-30e2e981b9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1816\n",
      "Validation size: 227\n",
      "Test size: 234\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty dataframes to store results\n",
    "train_df = pd.DataFrame()\n",
    "val_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "# Apply split for each category\n",
    "for _, group in job_df.groupby('Target_cat'):\n",
    "    train, val, test = split_data(group)\n",
    "    train_df = pd.concat([train_df, train])\n",
    "    val_df = pd.concat([val_df, val])\n",
    "    test_df = pd.concat([test_df, test])\n",
    "\n",
    "# Display the size of each split\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc0879-7e4d-4750-9515-b1a48d1714f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b5b75d6-db09-4851-a591-5381e5a09ac1",
   "metadata": {},
   "source": [
    "Convert Dataframe to Hugging face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "377640de-762a-4fd0-9847-6b02103eef11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_hf_dataset(train_df, val_df, test_df):\n",
    "    df_train = train_df.copy()\n",
    "    df_val = val_df.copy()\n",
    "    df_test = test_df.copy()\n",
    "    print(\"[INFO] Train, Test, and Val set shape\", df_train.shape, df_test.shape, df_val.shape)\n",
    "    \n",
    "    dataset_train = Dataset.from_pandas(df_train.drop('Target_cat', axis=1).reset_index())\n",
    "    dataset_val = Dataset.from_pandas(df_val.drop('Target_cat', axis=1).reset_index())\n",
    "    dataset_test = Dataset.from_pandas(df_test.drop('Target_cat', axis=1).reset_index())\n",
    "    \n",
    "    # Combine them into a single DatasetDict                                                              \n",
    "    dataset = DatasetDict({\n",
    "        'train': dataset_train,\n",
    "        'val': dataset_val,\n",
    "        'test': dataset_test\n",
    "    })\n",
    "    return dataset \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "271dadda-8a9c-454f-938e-238a58536aae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train, Test, and Val set shape (1816, 4) (234, 4) (227, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset = return_hf_dataset(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0af984f5-620f-4465-9e54-d94686bd6916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'Job Title', 'Job Description', 'Target'],\n",
       "    num_rows: 1816\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99da0c-4506-4b20-8591-31fb8bcac843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b607941a-9532-440e-bcc6-fbbb18f9187a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888e0e8dd2324cb49028a2a3ec33ab10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b014eab802463e80f9551beaf78478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/227 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b21211421e4928afd5a4cbb98678f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/234 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(f\"s3://{BUCKET_NAME}/dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5444f4-e110-4511-b257-180bb22f6ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef476f2-57a7-486c-b8bc-3510f9196cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f8103-0290-4020-a32b-b68741586e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f27d26-e783-429e-88c0-fc33c6d6974f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de13b4-fd78-4dba-9888-21f9570e542a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
