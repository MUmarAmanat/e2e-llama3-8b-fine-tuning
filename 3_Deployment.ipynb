{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5767d6-92ae-4896-bd26-a3fc74731fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (2.2.0)\n",
      "Collecting transformers (from peft)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (4.66.4)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting safetensors (from peft)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting huggingface-hub>=0.17.0 (from peft)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Collecting regex!=2019.12.17 (from transformers->peft)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers->peft)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, accelerate, transformers, peft\n",
      "Successfully installed accelerate-0.33.0 huggingface-hub-0.24.6 peft-0.12.0 regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd582d4-ab9c-4f05-959d-cd51f780df99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "from peft import PeftModel  \n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159fa856-0f86-4107-8151-2556159bd77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_LABELS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73189f-cd78-44ec-83ca-571b5affae64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0af59d09-f76b-40f8-a837-d34a8a970c41",
   "metadata": {},
   "source": [
    "## Login to HuggingFace for a gated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190aeeb7-b24f-4c74-a4db-07555cbc9434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f7772316d049bbb86a1ada974873c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d22c9-badb-4e80-8603-c877b89848e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Copy Model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6a0355-c83e-41a7-8d97-348ced283938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-769855604101/huggingface-pytorch-training-2024-08-31-07-27-32-313/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-east-1-769855604101/huggingface-pytorch-training-2024-08-31-07-27-32-313/output/model.tar.gz ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879d128-e5dc-4630-b7f5-14d34d99c9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d77285e9-8fe2-48ea-a498-6d30203d5a80",
   "metadata": {},
   "source": [
    "## Unzip .tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf3e3ff-442c-4eb0-b659-69b3be0b54b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ./llama_3b_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8e4cb8-c094-4cd8-af10-1c33e216af38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_tokens_map.json\n",
      "tokenizer.json\n",
      "tokenizer_config.json\n",
      "adapter_model.safetensors\n",
      "README.md\n",
      "checkpoint-29/\n",
      "checkpoint-29/special_tokens_map.json\n",
      "checkpoint-29/tokenizer.json\n",
      "checkpoint-29/tokenizer_config.json\n",
      "checkpoint-29/adapter_model.safetensors\n",
      "checkpoint-29/README.md\n",
      "checkpoint-29/adapter_config.json\n",
      "checkpoint-29/trainer_state.json\n",
      "checkpoint-29/optimizer.pt\n",
      "checkpoint-29/scheduler.pt\n",
      "checkpoint-29/training_args.bin\n",
      "checkpoint-29/rng_state.pth\n",
      "adapter_config.json\n",
      "training_args.bin\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf ./model.tar.gz -C ./llama_3b_ft/ --warning=no-unknown-keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a781158-b16c-4fde-b863-bc3c2529610a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c054ea2-5a50-435d-967a-41eacdf201a1",
   "metadata": {},
   "source": [
    "## Load Peft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622c01ef-cfb7-4edf-a6f8-f76764e152dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b176962b22e9454bbf415a56bcd8da91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a98a1ac2874c93a96f6af0fd9e3378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9828d8c5df469398b25abd78a37c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382464a5e8754891bf6f0700bb991f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae774a6026e74927beae7e5d8acaa68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b8129c8cc348e781b32f5512932bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0620ccc91edc4b3e8fc69428e680a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f9cc369fff496fa46fe1a3490e92f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "adapter_model = AutoPeftModelForSequenceClassification.from_pretrained(\"./llama_3b_ft/\",\n",
    "                                                              num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa72ae-d4c0-4f84-b558-2b8781b1380e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f613166a-17bd-402a-b056-339af6e61939",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load category map\n",
    "Load locally or from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1814e3fc-ab68-4b5f-95ce-2f3616ba993d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3 = boto3.resource('s3')\n",
    "# category_map = pickle.loads(s3.Bucket(\"cast-ai\").Object(\"job_category.pickle\").get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929afefd-dcff-480a-b179-cced99fe5549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./job_category.pickle', 'rb') as fp:\n",
    "    category_map = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e2c8a-51aa-4338-a01b-b5799f79559c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381fe443-5d2f-4a64-906d-39b6113669d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8e1735-4aec-4319-847c-cac489ee9672",
   "metadata": {},
   "source": [
    "## Load Huggingface model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd9a19d-e5b0-4f50-a0a5-6428a8da72d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PEFT_MODEL_ID = \"./llama_3b_ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0875f6-27e7-48af-bac4-709d100db392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e236e0c5384be0a73d379291a28004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoPeftModelForSequenceClassification.from_pretrained(PEFT_MODEL_ID,  num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff40ca-2bf8-4653-8409-8a33f2341d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c74a6f0c-23f7-4739-ae31-4ea95fde3def",
   "metadata": {},
   "source": [
    "## Merging Peft Adapter and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b41b7e5-8e95-4e28-b248-a6e3884de601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5c8fe-87e1-40b2-9b8d-434642c904b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "503e5bde-8930-4fcc-b776-589db7733421",
   "metadata": {},
   "source": [
    "## Setting labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45126b6f-ff43-45be-a8d8-2b7cc24cb2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_model.config.id2label = category_map\n",
    "full_model.config.label2id = dict((v,k) for k,v in category_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93303e-cf41-47dd-a2ff-914bc7c7b150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6a1372-0d25-4d16-842d-4f423a0d2ed2",
   "metadata": {},
   "source": [
    "## Save Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6151c063-7c11-4bd4-96b2-784ee0afc3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_model.save_pretrained(\"./llama_3b_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cee6f9-330b-4478-b866-cbbb1fa20b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f0bbbc-1993-402c-a74e-8cf2b3620c26",
   "metadata": {},
   "source": [
    "## Testing Merged Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952e8631-b78a-4b4b-81cd-52fc5e88d1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b3fe0e95dc4b06b659821acf4616bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbaa759ea6b4c5683c91a8e8cd50fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2710cda73014751a40b1133392fd66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", \n",
    "                                          return_tensors=\"pt\", padding=True, \n",
    "                                          truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "019d0796-0f50-43f4-a188-5343673cbc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = \"\"\"JOB DESCRIPTION:\n",
    "\n",
    "Strong framework outside of iOS is always a plus\n",
    "\n",
    "iOS experience and generalist engineers with backgrounds in related technologies is a plus\n",
    "\n",
    "A disciplined approach to development, documentation and file structure\n",
    "\n",
    "Strong visual design sense and excellent taste\n",
    "\n",
    "A constant desire to improve, learn more and take things higher\n",
    "\n",
    "An excellent understanding of networking, mobile network issues, concurrency and threading\n",
    "\n",
    "Experience working with internationalized apps\n",
    "\n",
    "RESPONSIBILITIES\n",
    "Design and build advanced applications for the iOS platform.\n",
    "Collaborate with cross-functional teams to define, design, and ship new features..\n",
    "Work on bug fixing and improving application performance.\n",
    "Continuously discover, evaluate, and implement new technologies to maximize development efficiency.\n",
    "Have published one or more iOS apps in the app store.\n",
    "A deep familiarity with Objective-C and Cocoa Touch.\n",
    "Experience working with iOS frameworks such as Core Data, Core Animation, Core Graphics and Core Text.\n",
    "Experience with third-party libraries and APIs.\n",
    "Working knowledge of the general mobile landscape, architectures, trends, and emerging technologies.\n",
    "Solid understanding of the full mobile development life cycle.\n",
    "Responsible for working on different layers of the iOS apps.\n",
    "Help architect and maintain our set of native mobile applications.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0236fe4f-c801-4385-a4b9-33b71773b215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(inp, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "out = full_model(**inputs)\n",
    "np.argmax(out.logits.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "888d0390-da7d-446e-9681-b6f7154a2227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Backend Developer',\n",
       " 1: 'Database Administrator',\n",
       " 2: 'DevOps Engineer',\n",
       " 3: 'Django Developer',\n",
       " 4: 'Flutter Developer',\n",
       " 5: 'Full Stack Developer',\n",
       " 6: 'Java Developer',\n",
       " 7: 'JavaScript Developer',\n",
       " 8: 'Machine Learning',\n",
       " 9: 'Network Administrator',\n",
       " 10: 'Node js developer',\n",
       " 11: 'PHP Developer',\n",
       " 12: 'Software Engineer',\n",
       " 13: 'Wordpress Developer',\n",
       " 14: 'iOS Developer'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a09c7f-0e60-4c23-a102-79431a60ddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494a043a-d221-48ef-9b4f-da58d1066d4a",
   "metadata": {},
   "source": [
    "## Create tarball for Deployment\n",
    "- First go into model directory using terminal\n",
    "- create a tar ball \n",
    "- upload to s3\n",
    "\n",
    "**NOTE**: Better to do it from terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cea6f8e-5288-4156-ac58-fcfc5455e3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a804ae71-211f-4185-bcf9-bb30c88cb8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asdsad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5751b210-07dd-463a-b5b8-b9a9f5ccb81e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !tar zcvf model.tar.gz * --exclude='checkpoint-*'\n",
    "# tar zcvf model.tar.gz * --exclude='checkpoint-*' --checkpoint=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7a242-f6cf-4f0c-b1c1-04066a70be9d",
   "metadata": {},
   "source": [
    "### upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5049d2-23ab-434f-8988-bd6eb7c2f196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: llama_3b_ft/model.tar.gz to s3://job-skill-s3/llama_3b_ft/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./llama_3b_ft/model.tar.gz s3://<S3-PATH>/llama_3b_ft/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e761c7a7-8b35-4ce9-a05e-2079e98d7f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {'HF_TASK': 'text-classification', \"HF_TOKEN\": \"<SPECIFY-YOUR-HG-TOKEN>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9b0467-25f6-47cb-b1cc-7ed7c12e857f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94c900-1cff-4187-afd0-fbf7373e1ed6",
   "metadata": {},
   "source": [
    "Use the same version of everything used during trianing for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00e6b475-3ce0-4d2d-8b49-c2a0d0e276a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(model_data=\"s3://<S3-PATH>/llama_3b_ft/model.tar.gz\",  # path to your trained sagemaker model\n",
    "                                     role=role, # iam role with permissions to create an Endpoint\n",
    "                                     transformers_version=\"4.37\", # transformers version used\n",
    "                                     pytorch_version=\"2.1\", # pytorch version used\n",
    "                                     py_version=\"py310\", # python version of the DLC,\n",
    "                                     env=env,\n",
    "                                )\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(initial_instance_count=1,\n",
    "                                     instance_type=\"ml.p3.8xlarge\",\n",
    "                                     volume_size=256  ## Specify atleast 100 GBs otherwise it won't load model correctly\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fce36-e02d-4cbe-81f2-17a80d3ba51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967362ae-3f22-4839-822c-a3a73c221ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f303ecb3-aba1-4ba2-94f8-4f485dd9571d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = \"\"\"Experience: 2-5 years\n",
    "\n",
    "Job Location:- Aurangabad/Pune\n",
    "\n",
    "Vacancies:- 02\n",
    "\n",
    "Note: Fresher Do Not Apply\n",
    "\n",
    "Job Description\n",
    "\n",
    "Looking for experienced developers who are passionate to work with an IT / Software Development company.\n",
    "\n",
    "Basic Requirements:\n",
    "Having prior working experience on WordPress\n",
    "Should be proficient verbally and written communication skills.\n",
    "Should be capable of writing an efficient code using best software development with good coding practices.\n",
    "Able to integrate data from various back-end services and databases.\n",
    "\n",
    "\n",
    "â€¢ WordPress\n",
    "â€¢ Plugin-in development\n",
    "â€¢ PHP\n",
    "â€¢ HTML/HTML5\n",
    "â€¢ Javascript/jQuery\n",
    "â€¢ Bootstrap\n",
    "â€¢ MySQL\n",
    "\n",
    "Qualification:\n",
    "â€¢ UG: B.Sc (CS/CSC/IT), BCA, BCS, BE, B.Tech (CS/CSE/IT)\n",
    "â€¢ M.Sc (CS/CSC/IT), MCA, MCS, ME, M.Tech (CS/CSE/IT)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf6836d3-9f3a-488d-87b1-b5508c794f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"inputs\": inp,\n",
    "        \"parameters\": {\n",
    "                       \"max_length\": 512,\n",
    "                        \"truncation\": True,\n",
    "                        \"hf_token\": \"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\"\n",
    "                      }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51bd3764-728d-427c-9fef-c713314586a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 1 has a total capacty of 15.78 GiB of which 109.00 MiB is free. Process 14053 has 15.67 GiB memory in use. Of the allocated memory 14.86 GiB is allocated by PyTorch, and 13.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-inference-2024-09-01-13-32-57-306 in account 769855604101 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 1 has a total capacty of 15.78 GiB of which 109.00 MiB is free. Process 14053 has 15.67 GiB memory in use. Of the allocated memory 14.86 GiB is allocated by PyTorch, and 13.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-inference-2024-09-01-13-32-57-306 in account 769855604101 for more information."
     ]
    }
   ],
   "source": [
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23eec26-ffee-4eec-8be3-8502454a195a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c86c419b-c137-42b7-bad3-cd0ef1e3f62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9b0fd87-43a3-45fc-9737-3b15194534b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0548f3fe-0f27-4e51-87a7-6535d98b5ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ba80067b-16f3-4ed5-8d0a-b21465950605",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(inp, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "out = full_model(**inputs)\n",
    "np.argmax(out.logits.detach().numpy(), axis=1)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7d94be4f-51b1-4bc0-b739-e69562cc28a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A/V|Unverified',\n",
       " 1: 'A/V|Unvetted',\n",
       " 2: 'A/V|Verified',\n",
       " 3: 'CCTV|Unverified',\n",
       " 4: 'CCTV|Unvetted',\n",
       " 5: 'CCTV|Verified',\n",
       " 6: 'Cabling|Unverified',\n",
       " 7: 'Cabling|Unvetted',\n",
       " 8: 'Cabling|Verified',\n",
       " 9: 'Electrical|Unverified',\n",
       " 10: 'Fiber|Unverified',\n",
       " 11: 'Imaging (PC/Serv)|Unverified',\n",
       " 12: 'Imaging (PC/Service)|Unverified',\n",
       " 13: 'Network/Router|Unverified',\n",
       " 14: 'Network/Router|Unvetted',\n",
       " 15: 'Network/Router|Verified',\n",
       " 16: 'PBX/Phone|Unverified',\n",
       " 17: 'PBX/Phone|Unvetted',\n",
       " 18: 'PBX/Phone|Verified',\n",
       " 19: 'PC Service|Unverified',\n",
       " 20: 'PC Service|Unvetted',\n",
       " 21: 'PC Service|Verified',\n",
       " 22: 'Paging|Unverified',\n",
       " 23: 'Paging|Unvetted',\n",
       " 24: 'Printer Service|Unverified',\n",
       " 25: 'Printer Service|Unvetted',\n",
       " 26: 'Printer Service|Verified',\n",
       " 27: 'Security|Unverified',\n",
       " 28: 'Smart Hands|Unverified'}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e49e0-4d36-4575-b0d0-4085be1e4bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b7cb6-448b-4761-ae83-83e704f03f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
